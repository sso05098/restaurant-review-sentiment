# 🍽️ 음식점 리뷰 감정분석 프로젝트

## 🧠 모델 개요
- 한국어 음식점 리뷰 데이터 약 360,000개를 바탕으로 감정 분류 모델 개발
- 감정 라벨: 0 = 부정, 1 = 중립, 2 = 긍정
- 사용 모델: LSTM, BERT (KcELECTRA)

## 모델 성능 비교

| 항목                | LSTM                              | BERT (KcELECTRA)                  |
|---------------------|-----------------------------------|-----------------------------------|
| 전처리 방식          | 직접 토크나이징 + 패딩              | HuggingFace 토크나이저 사용       |
| 평균 정확도          | 약 84% (imbalanced 기준)           | 약 71% (balanced 기준)            |
| 클래스별 F1 점수     | 긍정: 0.92, 중립: 0.28, 부정: 0.56  | 긍정: 0.73, 중립: 0.60, 부정: 0.78 |
| 장점                | 속도 빠름, 구현 간단                 | 문맥 이해력 우수, 성능 균형 잡힘   |
| 단점                | 중립 감정 분류 성능 낮음             | 학습 시간 길고 리소스 많이 사용    |
-
| 항목          | LSTM (불균형 데이터)      | BERT (균형 데이터, KcELECTRA) |
| ----------- | ------------------- | ------------------------ |
| 전체 정확도      | 높음 (84%)            | 낮음 (71%)                 |
| 중립/부정 인식    | 부정확함 (중립 f1 = 0.28) | 잘함 (중립 f1 = 0.60)        |
| 실제 감정 분석 성능 | 떨어짐 (긍정 편향)         | 더 현실적인 성능 (균형 잡힘)        |
-
📌 그래서 결론은?
정확도만 보면 LSTM이 더 좋아 보여도,
실제로는 BERT가 감정 분류를 더 정확하고 공정하게 함
(특히 중립/부정 감정 분류에서 확실한 우세)

## 📊 시각화 자료

- LSTM 학습 정확도 / 손실 그래프  
- 혼동행렬 (Confusion Matrix)  
- 예측 결과 예시:
