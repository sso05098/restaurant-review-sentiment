# 🍽️ 음식점 리뷰 감정분석 프로젝트

## 모델 개요
- 한국어 음식점 리뷰 데이터 약 360,000개를 바탕으로 감정 분류 모델 개발
- 감정 라벨: 0 = 부정, 1 = 중립, 2 = 긍정
- 사용 모델: LSTM, BERT (KcELECTRA)

## 모델 성능 비교

| 항목                | LSTM                              | BERT (KcELECTRA)                  |
|---------------------|-----------------------------------|-----------------------------------|
| 전처리 방식          | 직접 토크나이징 + 패딩              | HuggingFace 토크나이저 사용       |
| 평균 정확도          | 약 84% (imbalanced 기준)           | 약 71% (balanced 기준)            |
| 클래스별 F1 점수     | 긍정: 0.92, 중립: 0.28, 부정: 0.56  | 긍정: 0.73, 중립: 0.60, 부정: 0.78 |
| 장점                | 속도 빠름, 구현 간단                 | 문맥 이해력 우수, 성능 균형 잡힘   |
| 단점                | 중립 감정 분류 성능 낮음             | 학습 시간 길고 리소스 많이 사용    |

| 항목          | LSTM (불균형 데이터)      | BERT (균형 데이터, KcELECTRA) |
| ----------- | ------------------- | ------------------------ |
| 전체 정확도      | 높음 (84%)            | 낮음 (71%)                 |
| 중립/부정 인식    | 부정확함 (중립 f1 = 0.28) | 잘함 (중립 f1 = 0.60)        |
| 실제 감정 분석 성능 | 떨어짐 (긍정 편향)         | 더 현실적인 성능 (균형 잡힘)        |

📌 그래서 결론은?
정확도만 보면 LSTM이 더 좋아 보여도,
실제로는 BERT가 감정 분류를 더 정확하고 공정하게 함
(특히 중립/부정 감정 분류에서 확실한 우세)

## 분류 평가 지표
- ### 🔹 LSTM
              precision    recall  f1-score   support

          부정       0.69      0.47      0.56      4174
          중립       0.51      0.20      0.28      9912
          긍정       0.87      0.97      0.92     59728
    accuracy                           0.84     73814
   macro avg       0.69      0.55      0.59     73814
weighted avg       0.81      0.84      0.81     73814

- ### 🔹 BERT
                precision    recall  f1-score   support

          부정       0.82      0.74      0.78      4170
          중립       0.66      0.55      0.60      4171
          긍정       0.66      0.83      0.73      4171
     accuracy                           0.71     12512
    macro avg       0.71      0.71      0.70     12512
 weighted avg       0.71      0.71      0.70     12512

## 📊 시각화 자료
- ### 🔹 LSTM 정확도/손실 그래프
![LSTM Accuracy](plots/lstm1.png) ![LSTM Accuracy](plots/lstm2.png)
- ### 🔹 BERT 정확도/손실 그래프
![BERT Accuracy](plots/bert1.png) ![BERT Accuracy](plots/bert2.png)
- ### 🔹 워드클라우드
![wordcloud](plots/wordcloud.png)
